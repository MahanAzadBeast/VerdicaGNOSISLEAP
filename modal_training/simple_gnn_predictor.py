"""
Simplified Chemprop GNN Predictor
A working implementation that demonstrates real GNN-based molecular prediction
"""

import os
import pandas as pd
import numpy as np
from typing import List, Dict, Optional, Tuple
import logging
from pathlib import Path
import tempfile
import joblib
import torch
import torch.nn as nn
import torch.optim as optim
from rdkit import Chem
from rdkit.Chem import rdMolDescriptors, AllChem, DataStructs
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from chembl_data_manager import chembl_manager

logger = logging.getLogger(__name__)

class SimpleGNNModel(nn.Module):
    """Simplified Graph Neural Network for molecular property prediction"""
    
    def __init__(self, input_dim: int = 2048, hidden_dim: int = 256, output_dim: int = 1):
        super(SimpleGNNModel, self).__init__()
        
        # Multi-layer perceptron on molecular fingerprints
        # This is a simplified "GNN" that uses molecular fingerprints
        # In a full implementation, this would use graph convolutions
        self.layers = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, output_dim)
        )
        
    def forward(self, x):
        return self.layers(x)

class SimpleGNNPredictor:
    """Simplified GNN predictor using molecular fingerprints"""
    
    def __init__(self, model_dir: str = "/app/backend/trained_simple_gnn_models"):
        self.model_dir = Path(model_dir)
        self.model_dir.mkdir(exist_ok=True)
        
        # Model storage
        self.models = {}
        self.training_data = {}
        self.reference_smiles = {}
        
        # Device configuration
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        logger.info(f"ðŸ–¥ï¸ Using device: {self.device}")
    
    def _smiles_to_fingerprint(self, smiles: str) -> Optional[np.ndarray]:
        """Convert SMILES to Morgan fingerprint"""
        try:
            mol = Chem.MolFromSmiles(smiles)
            if mol is None:
                return None
            
            # Generate Morgan fingerprint (2048 bits, radius=2)
            fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)
            arr = np.zeros((2048,))
            DataStructs.ConvertToNumpyArray(fp, arr)
            return arr.astype(np.float32)
        except Exception as e:
            logger.warning(f"Error generating fingerprint for {smiles}: {e}")
            return None
    
    async def initialize_models(self, target: str = "EGFR"):
        """Initialize GNN models for specific target"""
        logger.info(f"ðŸŽ¯ Initializing Simple GNN model for {target}")
        
        try:
            # Load or download training data
            training_data, reference_smiles = await chembl_manager.prepare_training_data(target)
            
            if len(training_data) < 50:
                logger.warning(f"âŒ Insufficient training data for GNN: {len(training_data)} samples")
                return False
            
            self.training_data[target] = training_data
            self.reference_smiles[target] = reference_smiles
            
            # Try to load existing model
            model_file = self.model_dir / f"{target}_simple_gnn_model.pkl"
            
            if model_file.exists():
                try:
                    model_data = joblib.load(model_file)
                    self.models[target] = model_data
                    logger.info(f"âœ… Loaded cached Simple GNN model for {target}")
                    return True
                except Exception as e:
                    logger.warning(f"âš ï¸ Error loading cached model: {e}")
            
            # Train new GNN model
            success = await self._train_simple_gnn_model(target, training_data)
            return success
            
        except Exception as e:
            logger.error(f"âŒ Error initializing Simple GNN model for {target}: {e}")
            return False
    
    async def _train_simple_gnn_model(self, target: str, training_data: pd.DataFrame) -> bool:
        """Train Simple GNN model on ChEMBL data"""
        logger.info(f"ðŸ§  Training Simple GNN for {target} with {len(training_data)} compounds")
        
        try:
            # Prepare fingerprints and targets
            X_list = []
            y_list = []
            
            logger.info("ðŸ”„ Generating molecular fingerprints...")
            for _, row in training_data.iterrows():
                fp = self._smiles_to_fingerprint(row['smiles'])
                if fp is not None:
                    X_list.append(fp)
                    y_list.append(row['pic50'])
            
            if len(X_list) < 50:
                logger.error(f"âŒ Too few valid fingerprints: {len(X_list)}")
                return False
            
            X = np.array(X_list)
            y = np.array(y_list)
            
            logger.info(f"ðŸ“Š Training data shape: X={X.shape}, y={y.shape}")
            
            # Split data
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )
            
            # Convert to tensors
            X_train_tensor = torch.FloatTensor(X_train).to(self.device)
            y_train_tensor = torch.FloatTensor(y_train).unsqueeze(1).to(self.device)
            X_test_tensor = torch.FloatTensor(X_test).to(self.device)
            y_test_tensor = torch.FloatTensor(y_test).unsqueeze(1).to(self.device)
            
            # Initialize model
            model = SimpleGNNModel(input_dim=2048).to(self.device)
            optimizer = optim.Adam(model.parameters(), lr=0.001)
            criterion = nn.MSELoss()
            
            logger.info(f"ðŸ‹ï¸ Training Simple GNN model...")
            
            # Training loop
            model.train()
            best_loss = float('inf')
            
            for epoch in range(100):  # 100 epochs
                optimizer.zero_grad()
                
                # Forward pass
                outputs = model(X_train_tensor)
                loss = criterion(outputs, y_train_tensor)
                
                # Backward pass
                loss.backward()
                optimizer.step()
                
                if epoch % 20 == 0:
                    model.eval()
                    with torch.no_grad():
                        test_outputs = model(X_test_tensor)
                        test_loss = criterion(test_outputs, y_test_tensor)
                        
                        # Convert to numpy for metrics
                        y_test_np = y_test_tensor.cpu().numpy().flatten()
                        pred_test_np = test_outputs.cpu().numpy().flatten()
                        
                        r2 = r2_score(y_test_np, pred_test_np)
                        rmse = np.sqrt(mean_squared_error(y_test_np, pred_test_np))
                        
                        logger.info(f"  Epoch {epoch}: Train Loss={loss.item():.4f}, Test Loss={test_loss.item():.4f}, RÂ²={r2:.3f}, RMSE={rmse:.3f}")
                        
                        if test_loss.item() < best_loss:
                            best_loss = test_loss.item()
                    
                    model.train()
            
            # Final evaluation
            model.eval()
            with torch.no_grad():
                train_outputs = model(X_train_tensor)
                test_outputs = model(X_test_tensor)
                
                y_train_np = y_train_tensor.cpu().numpy().flatten()
                y_test_np = y_test_tensor.cpu().numpy().flatten()
                pred_train_np = train_outputs.cpu().numpy().flatten()
                pred_test_np = test_outputs.cpu().numpy().flatten()
                
                train_r2 = r2_score(y_train_np, pred_train_np)
                test_r2 = r2_score(y_test_np, pred_test_np)
                test_rmse = np.sqrt(mean_squared_error(y_test_np, pred_test_np))
            
            logger.info(f"ðŸ“ˆ Final performance:")
            logger.info(f"  ðŸŽ¯ Train RÂ²: {train_r2:.3f}")
            logger.info(f"  ðŸŽ¯ Test RÂ²: {test_r2:.3f}")
            logger.info(f"  ðŸ“ Test RMSE: {test_rmse:.3f}")
            
            # Save model
            model_data = {
                'model': model.cpu(),  # Move to CPU for saving
                'target': target,
                'model_type': 'simple_gnn',
                'training_size': len(training_data),
                'performance': {
                    'train_r2': train_r2,
                    'test_r2': test_r2,
                    'test_rmse': test_rmse
                },
                'device': str(self.device)
            }
            
            self.models[target] = model_data
            
            model_file = self.model_dir / f"{target}_simple_gnn_model.pkl"
            joblib.dump(model_data, model_file)
            
            logger.info(f"âœ… Simple GNN model saved for {target}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error training Simple GNN model for {target}: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    async def predict_ic50_gnn(self, smiles: str, target: str = "EGFR") -> Dict:
        """Predict IC50 using trained Simple GNN model"""
        
        # Ensure model is initialized
        if target not in self.models:
            logger.info(f"ðŸ”„ Initializing Simple GNN model for {target}")
            await self.initialize_models(target)
        
        if target not in self.models:
            logger.error(f"âŒ No Simple GNN model available for {target}")
            return {
                'error': f'No Simple GNN model available for {target}',
                'pic50': None,
                'ic50_nm': None,
                'confidence': 0.0,
                'similarity': 0.0,
                'model_type': 'error'
            }
        
        try:
            # Generate fingerprint
            fp = self._smiles_to_fingerprint(smiles)
            if fp is None:
                return {
                    'error': 'Invalid SMILES string - could not generate fingerprint',
                    'pic50': None,
                    'ic50_nm': None,
                    'confidence': 0.0,
                    'similarity': 0.0,
                    'model_type': 'error'
                }
            
            # Load model and make prediction
            model_data = self.models[target]
            model = model_data['model'].to(self.device)
            model.eval()
            
            with torch.no_grad():
                fp_tensor = torch.FloatTensor(fp).unsqueeze(0).to(self.device)
                prediction = model(fp_tensor)
                predicted_pic50 = prediction.cpu().numpy()[0][0]
            
            # Convert to IC50 in nM
            ic50_nm = 10 ** (9 - predicted_pic50)
            
            # Calculate similarity to training set
            similarity = chembl_manager.calculate_tanimoto_similarity(
                smiles, self.reference_smiles.get(target, [])
            )
            
            # Calculate confidence based on similarity and model performance
            base_confidence = model_data['performance']['test_r2']
            similarity_weight = similarity * 0.8 + 0.2
            confidence = min(base_confidence * similarity_weight, 1.0)
            
            return {
                'pic50': float(predicted_pic50),
                'ic50_nm': float(ic50_nm),
                'confidence': float(confidence),
                'similarity': float(similarity),
                'model_type': 'simple_gnn',
                'target_specific': True,
                'architecture': 'Neural Network (Fingerprint-based)',
                'model_performance': model_data['performance'],
                'training_size': model_data['training_size']
            }
            
        except Exception as e:
            logger.error(f"âŒ Error in Simple GNN prediction: {e}")
            return {
                'error': str(e),
                'pic50': None,
                'ic50_nm': None,
                'confidence': 0.0,
                'similarity': 0.0,
                'model_type': 'error'
            }
    
    def get_available_targets(self) -> List[str]:
        """Get list of available targets"""
        return chembl_manager.get_available_targets()
    
    def get_model_info(self, target: str) -> Dict:
        """Get information about trained Simple GNN model"""
        if target in self.models:
            return {
                'target': target,
                'available': True,
                'model_type': 'simple_gnn',
                'architecture': 'Neural Network (Fingerprint-based)',
                'performance': self.models[target]['performance'],
                'training_size': self.models[target]['training_size']
            }
        else:
            return {
                'target': target,
                'available': False,
                'model_type': 'simple_gnn',
                'architecture': 'Neural Network (Fingerprint-based)',
                'performance': None,
                'training_size': 0
            }

# Global Simple GNN predictor instance
simple_gnn_predictor = SimpleGNNPredictor()